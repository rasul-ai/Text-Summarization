# Text-Summarization
**Author:** [Md Rasul Islam Bapary]  
**Date:** [14.03.2024]

## Choosing a Kaggle Dataset for Large Language Model Training
In this project, I have selected the CNN-DailyMail News Text Summarization dataset from Kaggle for training or fine-tuning a Large Language Model (LLM). In this file, I will provide an overview of why I have chosen this dataset and my considerations during the selection process.
### Dataset Overview
The CNN-DailyMail dataset is one of the widely used benchmark for text summarization tasks. It consists of news articles from CNN and DailyMail along with human-generated summaries. Each article has a single highlight .The dataset is well-structured, containing a large number of articles across various topics. \
When selecting this dataset, I have looked into several factors,

    1. Data Size:
       The CNN-DailyMail dataset is sufficiently large, containing thousands of articles along with corresponding
       summaries. It contains,
       Train set : 287,113
       Validation set : 13,368
       Test set : 11,490
    2. Diversity of Content:
       This dataset is a collection of news articles covering a wide range of topics, including politics, sports, technology,
       entertainment, and more.
    3. Availability of Ground Truth Summaries:
       Each news article in the dataset comes with human-generated summaries, serving as ground truth reference points for
       evaluating the quality of the model's generated summaries.
    4. Relevance to Real-World Applications:
       News summarization is a real-world application with widespread relevance. It can be useful for tasks such as content
       recommendation systems, news aggregation platforms, and information retrieval.
    5. Potential for Creative Exploration using Prompt Engineering:
       The nature of this dataset allows for creative exploration using Generative AI also.
