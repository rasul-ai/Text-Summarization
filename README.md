# Text-Summarization
**Author:** [Md Rasul Islam Bapary]  
**Date:** [14.03.2024]

## Choosing a Kaggle Dataset for Large Language Model Training
In this project, I have selected the CNN-DailyMail News Text Summarization dataset from Kaggle for training or fine-tuning a Large Language Model (LLM). In this file, I will provide an overview of why I have chosen this dataset and my considerations during the selection process.
### Dataset Overview
The CNN-DailyMail dataset is one of the widely used benchmark for text summarization tasks. It consists of news articles from CNN and DailyMail along with human-generated summaries. Each article has a single highlight .The dataset is well-structured, containing a large number of articles across various topics.
When selecting this dataset, I have looked into several factors,

    1. Data Size:
       The CNN-DailyMail dataset is sufficiently large, containing thousands of articles along with corresponding summaries. It contains,
       Train set :	287,113
       Validation set :	13,368
       Test set :	11,490
    2. Relevance to Real-World Applications:
       News summarization is a real-world application with widespread relevance. Being able to accurately summarize news articles has practical implications for tasks such         as content recommendation systems, news aggregation platforms, and information retrieval.
